{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Lx5O56hcdN",
        "outputId": "f8885a15-84b9-4284-d871-42a16db51371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP-Projects'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)\u001b[K\rremote: Counting objects:  15% (2/13)\u001b[K\rremote: Counting objects:  23% (3/13)\u001b[K\rremote: Counting objects:  30% (4/13)\u001b[K\rremote: Counting objects:  38% (5/13)\u001b[K\rremote: Counting objects:  46% (6/13)\u001b[K\rremote: Counting objects:  53% (7/13)\u001b[K\rremote: Counting objects:  61% (8/13)\u001b[K\rremote: Counting objects:  69% (9/13)\u001b[K\rremote: Counting objects:  76% (10/13)\u001b[K\rremote: Counting objects:  84% (11/13)\u001b[K\rremote: Counting objects:  92% (12/13)\u001b[K\rremote: Counting objects: 100% (13/13)\u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), 360.82 KiB | 4.40 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/FaiqaMehboobAwan/NLP-Projects.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh2PT94phl3I",
        "outputId": "30c55afe-ef8e-4f21-9a2e-aa2998992607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Flood_Disaster_Sentiment_Analysis_in_Pakistan.ipynb\n",
            " floodrawdata.csv\n",
            " \u001b[0m\u001b[01;34mNLP-Projects\u001b[0m/\n",
            " README.md\n",
            "'twitter data scraping code using snscraper.txt'\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXeOyRy4p025"
      },
      "outputs": [],
      "source": [
        "rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsdCeMX0hnVb",
        "outputId": "e945dd8e-0b50-4dfd-8946-f7891e248471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP-Projects/NLP-Projects\n"
          ]
        }
      ],
      "source": [
        "cd NLP-Projects/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZG5ZDfkhpmz",
        "outputId": "22acdbc4-7ea6-4cc1-cf38-6510bd328ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Flood_Disaster_Sentiment_Analysis_in_Pakistan.ipynb\n",
            " README.md\n",
            "'twitter data scraping code using snscraper.txt'\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6My1Hxz-is08",
        "outputId": "1dc7c767-e396-421d-8a2d-3f1fb3461975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.9/dist-packages (0.6.1.20230314)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from snscrape) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from snscrape) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->snscrape) (2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO870j5ohqig",
        "outputId": "1cc64c4c-db92-4204-89fb-9d1d9f5c1d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-efaf5ca77727>:19: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
            "  tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
            "<ipython-input-25-efaf5ca77727>:19: DeprecatedFeatureWarning: username is deprecated, use user.username instead\n",
            "  tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.username])\n"
          ]
        }
      ],
      "source": [
        "import pip\n",
        "import snscrape as snscrape\n",
        "# import git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "# pip install --upgrade git+https://github.com/JustAnotherArchivist/snscrape@master #sourse of code\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "# Query by text search\n",
        "# Setting variables to be used below\n",
        "maxTweets = 45000\n",
        "\n",
        "# Creating list to append tweet data to\n",
        "tweets_list2 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(' earthquake in turkey since:2023-02-06 until:2023-02-27 ').get_items()):\n",
        "    if i > maxTweets:\n",
        "        break\n",
        "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
        "\n",
        "# code below will scrape flood data\n",
        "# for i, tweet in enumerate(sntwitter.TwitterSearchScraper(' flood in pakistan since:2022-01-01 until:2022-12-31 ').get_items()):\n",
        "#     if i > maxTweets:\n",
        "#         break\n",
        "#     tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
        "\n",
        "# Creating a dataframe from the tweets list above\n",
        "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Time and Date', 'Tweet Id', 'Text', 'Username'])\n",
        "\n",
        "# Display first 5 entries from dataframe\n",
        "tweets_df2.head()\n",
        "\n",
        "# Export dataframe into a CSV\n",
        "tweets_df2.to_csv('floodrawdata.csv', sep=',', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaGiylwel6PB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJN4XaOpplAU"
      },
      "outputs": [],
      "source": [
        "#worldcloud\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import string\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLdua1UCppTU"
      },
      "outputs": [],
      "source": [
        "#worldcloud\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import string\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGsxGyjmps1B",
        "outputId": "dcb23bc7-8375-463e-99fa-70b1e8e37b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.9/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from vaderSentiment) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2.10)\n"
          ]
        }
      ],
      "source": [
        "#vaderSentiment\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM6DT4WvpvZU",
        "outputId": "2d468127-9bc1-4bbb-905f-87e53e4053f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# NLTK\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "03855266c25741f9beb73e88543f384b",
            "5be2c1c8809c4b37b5d7d3f0a70b07f5",
            "6afc4388dedf4fc18dd27a2c6045af33",
            "c5344f95557c4c07bc25c5c147ef069f",
            "697198f4da2746fcac9965d607978026",
            "cac75c6479bf4924a548900afca6a936",
            "cb58a7ea8bdc4cbc91d69461b229db21",
            "124fe4986c294b4a9d80e3713816b2ff",
            "fbf4ad11caba4116900cea53adb88efe",
            "07b7d95da90b4b3a815cb1c6f984c2f0",
            "ae6b27eebe2146d9a254792a93e0b538"
          ]
        },
        "id": "3j6VyNbUqAYx",
        "outputId": "90df1b80-a1e5-459f-9560-2fb22b1d9289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Stanza in /usr/local/lib/python3.9/dist-packages (1.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from Stanza) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from Stanza) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from Stanza) (1.22.4)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (from Stanza) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from Stanza) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from Stanza) (2.25.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from Stanza) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.3.0->Stanza) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->Stanza) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->Stanza) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->Stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->Stanza) (2022.12.7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03855266c25741f9beb73e88543f384b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloading default packages for language: en (English) ...\n",
            "INFO:stanza:File exists: /root/stanza_resources/en/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ],
      "source": [
        "# Stanza\n",
        "!pip install Stanza\n",
        "import stanza\n",
        "stanza.download('en')\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOsCo-cYqH4r",
        "outputId": "b03d30ef-ce1c-441e-a301-8041bb65f250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: neattext in /usr/local/lib/python3.9/dist-packages (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#NeatText\n",
        "!pip install neattext\n",
        "import neattext.functions as nfx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY87NbDFqOIK",
        "outputId": "65adcef2-ea41-4fd2-b958-66cfaf6275f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.4.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.6)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Spacy\n",
        "!pip install spacy\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7v62HkJqS7k"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNn_u6CxqZDU"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('floodrawdata.csv')\n",
        "print(data.shape)\n",
        "data.isnull().any()\n",
        "data.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYpwJ3-eqe72"
      },
      "outputs": [],
      "source": [
        "#checking frequency of words\n",
        "\n",
        "cv = CountVectorizer(stop_words = 'english')\n",
        "words = cv.fit_transform(data.Text)\n",
        "\n",
        "sum_words = words.sum(axis=0)\n",
        "\n",
        "words_freq = [(word, sum_words[0, i]) for word, i in cv.vocabulary_.items()]\n",
        "words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
        "\n",
        "frequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 7), color = 'magenta')\n",
        "plt.title(\"Most Frequently Occuring Words - Top 20\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFGwwKhuq-d7"
      },
      "outputs": [],
      "source": [
        "# collecting the hashtags\n",
        "\n",
        "def hashtag_extract(x):\n",
        "    hashtags = []\n",
        "    \n",
        "    for i in x:\n",
        "        ht = re.findall(r\"#(\\w+)\", i)\n",
        "        hashtags.append(ht)\n",
        "\n",
        "    return hashtags\n",
        "  # extracting hashtags from non racist tweets\n",
        "HT_regular = hashtag_extract(data['Text'])\n",
        "# unnesting list\n",
        "HT_regular = sum(HT_regular,[])\n",
        "a = nltk.FreqDist(HT_regular)\n",
        "d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
        "                  'Count': list(a.values())})\n",
        "# selecting top 20 most frequent hashtags     \n",
        "d = d.nlargest(columns=\"Count\", n = 11) \n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
        "ax.set(ylabel = 'Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYd_ELczzCfH"
      },
      "outputs": [],
      "source": [
        "# Keep only tweets that involve these KEYWORDS for earthquake\n",
        "data = data[(data['Text'].str.contains(\"earthquakeinturkey\")) \n",
        "                            | (data['Text'].str.contains(\"earthquake\"))\n",
        "                            | (data['Text'].str.contains(\"Turkey\"))\n",
        "                            | (data['Text'].str.contains(\"Syria\"))\n",
        "                            | (data['Text'].str.contains(\"TurkeyEarthquake\"))\n",
        "                            | (data['Text'].str.contains(\"Earthquake\"))\n",
        "                            | (data['Text'].str.contains(\"SyriaEarthquake\"))\n",
        "                            | (data['Text'].str.contains(\"Turkeyearthquake2023\"))]\n",
        "len(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN4ozNn2rFHK"
      },
      "outputs": [],
      "source": [
        "# # Keep only tweets that involve these KEYWORDS\n",
        "# data = data[(data['Text'].str.contains(\"floodsinpakistan\")) \n",
        "#                             | (data['Text'].str.contains(\"floodpakistan\"))\n",
        "#                             | (data['Text'].str.contains(\"floodrelief\"))\n",
        "#                             | (data['Text'].str.contains(\"pakistan\"))\n",
        "#                             | (data['Text'].str.contains(\"floodvictims\"))\n",
        "#                             | (data['Text'].str.contains(\"floodsituation\"))\n",
        "#                             | (data['Text'].str.contains(\"flooding\"))]\n",
        "# len(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvGZ07M5rK2f"
      },
      "outputs": [],
      "source": [
        "#converting column names and text data to lower case\n",
        "data['Text'] = data['Text'].apply(lambda x: str(x.lower()))\n",
        "\n",
        "# Note, skipping this step as uppercase reflects sentiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ6nyRMv_Ikm"
      },
      "outputs": [],
      "source": [
        "!pip install tweet-preprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWE8JFm2_p-C"
      },
      "outputs": [],
      "source": [
        "import preprocessor as p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuBrY4S3rTCZ"
      },
      "outputs": [],
      "source": [
        "# Clean tweet text with tweet-preprocessor\n",
        "data['text_cleaned'] = data['Text'].apply(lambda x: p.clean(x))\n",
        "data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vOJRCLTrWT2"
      },
      "outputs": [],
      "source": [
        "# Remove unnecessary characters\n",
        "\n",
        "punct =['%','/',':','\\\\','&amp;','&',';']\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in punct:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text\n",
        "data['text_cleaned'] = data['text_cleaned'].apply(lambda x: remove_punctuations(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBl7T79fE7wk"
      },
      "outputs": [],
      "source": [
        "# Drop tweets which have empty text field\n",
        "data['text_cleaned'].replace('', np.nan, inplace=True)\n",
        "data['text_cleaned'].replace(' ', np.nan, inplace=True)\n",
        "data.dropna(subset=['text_cleaned'], inplace=True)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-FMZMt1E-gg"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate tweets\n",
        "data.drop_duplicates(subset='text_cleaned', keep=\"first\", inplace = True)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoHkFh2JFBR7"
      },
      "outputs": [],
      "source": [
        "data = data.reset_index(drop=True)\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alq0Dgz0FD4z"
      },
      "outputs": [],
      "source": [
        "#determining word count in text\n",
        "data['Word Counts'] = data['text_cleaned'].apply(lambda x: len([i for i in x.split()]))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud6PZ0rEFXaO"
      },
      "outputs": [],
      "source": [
        "#determining stop words( stop wordsdoes not add much information to the text)\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "data['Stop Words'] = data['text_cleaned'].apply(lambda x: len([i for i in x.split() if i not in STOP_WORDS]))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK_LjND8FaTA"
      },
      "outputs": [],
      "source": [
        "# Import new libraries\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "# Create a wordcloud of the movie titles\n",
        "data['text_cleaned'] = data['text_cleaned'].fillna(\"\").astype('str')\n",
        "title_corpus = ' '.join(data['text_cleaned'])\n",
        "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black', height=2000, width=4000).generate(title_corpus)\n",
        "# Plot the wordcloud\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.imshow(title_wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-HmYwWeFd20"
      },
      "outputs": [],
      "source": [
        "# Define function to get value counts\n",
        "def get_value_counts(col_name, analyzer_name):\n",
        "    count = pd.DataFrame(data[col_name].value_counts())\n",
        "    percentage = pd.DataFrame(data[col_name].value_counts(normalize=True).mul(100))\n",
        "    value_counts_df = pd.concat([count, percentage], axis = 1)\n",
        "    value_counts_df = value_counts_df.reset_index()\n",
        "    value_counts_df.columns = ['sentiment', 'counts', 'percentage']\n",
        "    value_counts_df.sort_values('sentiment', inplace = True)\n",
        "    value_counts_df['percentage'] = value_counts_df['percentage'].apply(lambda x: round(x,2))\n",
        "    value_counts_df = value_counts_df.reset_index(drop = True)\n",
        "    value_counts_df['analyzer'] = analyzer_name\n",
        "    return value_counts_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QHLbePeFm1H"
      },
      "outputs": [],
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Obtaining NLTK scores\n",
        "data['nltk_scores'] = data['text_cleaned'].apply(lambda x: sia.polarity_scores(x))\n",
        "\n",
        "# Obtaining NLTK compound score\n",
        "data['nltk_cmp_score'] = data['nltk_scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "# Set threshold to define neutral sentiment\n",
        "neutral_thresh = 0.05\n",
        "# Categorize scores into the sentiments of positive, neutral or negative\n",
        "data['nltk_sentiment'] = data['nltk_cmp_score'].apply(lambda c: 'Positive' if c >= neutral_thresh else ('Negative' if c <= -(neutral_thresh) else 'Neutral'))\n",
        "data['nltk_cmp_score'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mtmpzLEFr5Z"
      },
      "outputs": [],
      "source": [
        "nltk_sentiment_df = get_value_counts('nltk_sentiment','NLTK Vader')\n",
        "nltk_sentiment_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SjegT6h9bms"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z93jQhgbFvMd"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"dark\")\n",
        "ax = sns.barplot(x=\"sentiment\", y=\"percentage\", data=nltk_sentiment_df)\n",
        "ax.set_title('NLTK Vader')\n",
        "\n",
        "for index, row in nltk_sentiment_df.iterrows():\n",
        "    ax.text(row.name,row.percentage, round(row.percentage,1), color='black', ha=\"center\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCOoJ1HNrBsf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the indigo tweets data\n",
        "#IndigoTweets=pd.read_csv('floodrawdata.csv', encoding='latin')\n",
        "IndigoTweets = data['text_cleaned']\n",
        "print(IndigoTweets.shape)\n",
        "IndigoTweets.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR31RoDHrlc5"
      },
      "outputs": [],
      "source": [
        "# installing the library 'transformers' which contains BERT implementation\n",
        "!pip install transformers\n",
        " \n",
        "# installing the library tensorflow\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEM9Nq-erx5j"
      },
      "outputs": [],
      "source": [
        "# importing the pipeline module\n",
        "from transformers import pipeline\n",
        " \n",
        "# Downloading the sentiment analysis model\n",
        "SentimentClassifier = pipeline(\"sentiment-analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZVz3VF1r4mm"
      },
      "outputs": [],
      "source": [
        "# Calling the sentiment analysis function for 3 sentences\n",
        "SentimentClassifier([\"I hope we get all these concepts! Its killing the neurons of our brain\",\n",
        "                     \"We had a nice experience in this trip\",\n",
        "                     \"Houston we have a problem\"\n",
        "                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y1F7DJjr9s5"
      },
      "outputs": [],
      "source": [
        "# Defining a function to call for the whole dataframe\n",
        "def FunctionBERTSentiment(inpText):\n",
        "  return(SentimentClassifier(inpText)[0]['label'])\n",
        " \n",
        "# Calling the function\n",
        "FunctionBERTSentiment(inpText=\"Houston we have a problem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BuSfyX0sOfs"
      },
      "outputs": [],
      "source": [
        "# Calling BERT based sentiment score function for every tweet\n",
        "#IndigoTweets['Sentiment']=IndigoTweets['text_cleaned'].apply(FunctionBERTSentiment)\n",
        "IndigoTweets['Sentiment']=IndigoTweets.apply(FunctionBERTSentiment)\n",
        "IndigoTweets.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_FrC69K46Dn"
      },
      "outputs": [],
      "source": [
        "# Visualizing the overall sentiment distribution\n",
        "import matplotlib.pyplot as plt\n",
        "fig, subPlot =plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "fig.suptitle(\"Sentiment Classification of Flood Tweets\")\n",
        "\n",
        "# Grouping the data\n",
        "GroupedData=IndigoTweets.groupby('Sentiment').size()\n",
        "\n",
        "# Creating the charts\n",
        "GroupedData.plot(kind='bar', ax=subPlot[0], color=['crimson', 'lightblue'])\n",
        "GroupedData.plot(kind='pie', ax=subPlot[1], colors=['crimson', 'lightblue'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmnz7QQa4Xzr"
      },
      "source": [
        "**trying to get emotions from Tweets dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax94Cd2tvQuW"
      },
      "outputs": [],
      "source": [
        "!pip install NRCLex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypNDh12gxkn6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"floodrawdata.csv\")\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGASws3T7k5X"
      },
      "outputs": [],
      "source": [
        "data.Text.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VRo4vIJ8owh"
      },
      "outputs": [],
      "source": [
        "from nrclex import NRCLex\n",
        "str_tweet = ','.join(data['Text'])\n",
        "text_object = NRCLex(str_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L140GRCo9VOV"
      },
      "outputs": [],
      "source": [
        "data = text_object.raw_emotion_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bzuZi_mCdcQ"
      },
      "outputs": [],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ1yBZAe-VW7"
      },
      "outputs": [],
      "source": [
        "emotion_df = pd.DataFrame.from_dict(data, orient='index')\n",
        "emotion_df = emotion_df.reset_index()\n",
        "emotion_df = emotion_df.rename(columns={'index' : 'Emotion Classification' , 0: 'Emotion Count'})\n",
        "emotion_df = emotion_df.sort_values(by=['Emotion Count'], ascending=False)\n",
        "import plotly.express as px\n",
        "fig = px.bar(emotion_df, x='Emotion Count', y='Emotion Classification', color = 'Emotion Classification', orientation='h', width = 800, height = 400)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB2yya_D-Yfn"
      },
      "outputs": [],
      "source": [
        "text_object.affect_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DoYG1Nw-bhF"
      },
      "outputs": [],
      "source": [
        "affect_df = pd.DataFrame.from_dict(text_object.affect_dict, orient='index')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryiEDzXwBPfL"
      },
      "outputs": [],
      "source": [
        "affect_df.head(17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quCJmt4Z-ea0"
      },
      "outputs": [],
      "source": [
        "text_object.affect_frequencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PN3cKSW-gz4"
      },
      "outputs": [],
      "source": [
        "affect_df = pd.DataFrame.from_dict(text_object.affect_frequencies, orient='index')\n",
        "#emotion_df = pd.DataFrame.from_dict(data, orient='index')\n",
        "affect_df = affect_df.reset_index()\n",
        "affect_df = affect_df.rename(columns={'index' : 'Emotion Classification' , 0: 'Emotion Frequency'})\n",
        "affect_df = affect_df.sort_values(by=['Emotion Frequency'], ascending=False)\n",
        "import plotly.express as px\n",
        "fig = px.bar(affect_df, x='Emotion Frequency', y='Emotion Classification', color = 'Emotion Frequency', orientation='h', width = 800, height = 400)\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03855266c25741f9beb73e88543f384b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5be2c1c8809c4b37b5d7d3f0a70b07f5",
              "IPY_MODEL_6afc4388dedf4fc18dd27a2c6045af33",
              "IPY_MODEL_c5344f95557c4c07bc25c5c147ef069f"
            ],
            "layout": "IPY_MODEL_697198f4da2746fcac9965d607978026"
          }
        },
        "5be2c1c8809c4b37b5d7d3f0a70b07f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cac75c6479bf4924a548900afca6a936",
            "placeholder": "​",
            "style": "IPY_MODEL_cb58a7ea8bdc4cbc91d69461b229db21",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
          }
        },
        "6afc4388dedf4fc18dd27a2c6045af33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124fe4986c294b4a9d80e3713816b2ff",
            "max": 29911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbf4ad11caba4116900cea53adb88efe",
            "value": 29911
          }
        },
        "c5344f95557c4c07bc25c5c147ef069f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07b7d95da90b4b3a815cb1c6f984c2f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6b27eebe2146d9a254792a93e0b538",
            "value": " 200k/? [00:00&lt;00:00, 5.99MB/s]"
          }
        },
        "697198f4da2746fcac9965d607978026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac75c6479bf4924a548900afca6a936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb58a7ea8bdc4cbc91d69461b229db21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "124fe4986c294b4a9d80e3713816b2ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf4ad11caba4116900cea53adb88efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07b7d95da90b4b3a815cb1c6f984c2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6b27eebe2146d9a254792a93e0b538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}